# Installing and Configuring Ansible

Installing and Configuring Ansible is a crucial step in leveraging its power for configuration management. This lesson will guide you through the process of setting up Ansible on your control node, configuring access to your managed nodes, and verifying your installation. A properly configured Ansible environment is the foundation for automating infrastructure and application deployments.

## Ansible Installation

Ansible can be installed on various operating systems, including Linux, macOS, and Windows (using WSL - Windows Subsystem for Linux). The recommended approach is to install Ansible on a Linux control node, as it provides the most seamless experience.

### Installing Ansible on Linux (Ubuntu/Debian)

1.  **Update Package Index:** Before installing any new software, it's a good practice to update the package index.

```bash
    sudo apt update
```

2.  **Install Ansible:** Use the apt package manager to install Ansible.

```bash
    sudo apt install ansible -y
```

3.  **Verify Installation:** Check the installed version of Ansible to ensure it was installed correctly.

```bash
    ansible --version
```

1.  This command will display the Ansible version, Python version, and other relevant information.

### Installing Ansible on Linux (CentOS/RHEL)

1.  **Enable EPEL Repository:** Ansible is often available in the EPEL (Extra Packages for Enterprise Linux) repository. If you don't have EPEL enabled, you'll need to install it.

```bash
    sudo yum install epel-release -y
```

2.  **Install Ansible:** Use the yum package manager to install Ansible.

```bash
    sudo yum install ansible -y
```

3.  **Verify Installation:** Check the installed version of Ansible.

```bash
    ansible --version
```

## Installing Ansible on macOS

1.  **Install Homebrew:** If you don't have Homebrew installed, you'll need to install it first. Follow the instructions on the Homebrew website: [https://brew.sh/](https://brew.sh/)
2.  **Install Ansible:** Use Homebrew to install Ansible.

```bash
    brew install ansible
```

3.  **Verify Installation:** Check the installed version of Ansible.

```bash
    ansible --version
```

### Installing Ansible on Windows (using WSL)

1.  **Install WSL:** Enable the Windows Subsystem for Linux and install a Linux distribution (e.g., Ubuntu) from the Microsoft Store.
2.  **Install Ansible:** Follow the Linux installation instructions (Ubuntu/Debian) within your WSL environment.
3.  **Verify Installation:** Check the Ansible version to confirm the installation was successful.

```bash
    ansible --version
```

## Ansible Configuration

After installing Ansible, you need to configure it to manage your target servers. The primary configuration file is ansible.cfg, which controls various aspects of Ansible's behavior.

### The ansible.cfg File

The ansible.cfg file is the main configuration file for Ansible. It's typically located in /etc/ansible/ansible.cfg or in the same directory as your playbook. You can also create a local ansible.cfg file in your project directory to override the global settings.

1.  **Location:** Ansible searches for ansible.cfg in the following order:

    - ANSIBLE_CONFIG environment variable
    - ./ansible.cfg (current directory)
    - ~/.ansible.cfg (user's home directory)
    - /etc/ansible/ansible.cfg (system-wide)

2.  **Key Configuration Options:**

    - inventory: Specifies the location of your inventory file (default: /etc/ansible/hosts).
    - library: Specifies the location of your custom Ansible modules.
    - module_utils: Specifies the location of your custom Ansible module utilities.
    - remote_tmp: Specifies the temporary directory on the managed node where Ansible uploads modules to be executed (default: ~/.ansible/tmp).
    - local_tmp: Specifies the temporary directory on the control node.
    - forks: Specifies the number of parallel processes to use when executing tasks (default: 5). Increasing this can speed up playbook execution, but also increases resource usage.
    - become: Enables privilege escalation (e.g., using sudo) for tasks that require it (default: False).
    - become_method: Specifies the method used for privilege escalation (e.g., sudo, su, pbrun, doas).
    - become_user: Specifies the user to become when using privilege escalation (default: root).
    - ask_pass: Prompts for the SSH password if password authentication is used (default: False). It's highly recommended to use SSH keys instead of passwords.
    - private_key_file: Specifies the path to the SSH private key file.
    - host_key_checking: Enables or disables SSH host key checking (default: True). Disabling this is *not* recommended for security reasons, but can be useful in testing environments.

3.  **Example ansible.cfg:**

```ini
[defaults]
inventory = ./inventory
remote_tmp = /tmp/.ansible
forks = 10
become = True
become_method = sudo
become_user = root
host_key_checking = False
private_key_file = ~/.ssh/id_rsa
```

1.  This example configures Ansible to:

    - Use an inventory file named inventory in the current directory.
    - Use /tmp/.ansible as the temporary directory on the managed nodes.
    - Use 10 parallel processes.
    - Enable privilege escalation using sudo as the root user.
    - Disable host key checking.
    - Use the SSH private key file located at ~/.ssh/id_rsa.

### The Inventory File

The inventory file is a crucial component of Ansible. It defines the hosts and groups of hosts that Ansible will manage. The default location for the inventory file is /etc/ansible/hosts, but you can specify a different location in the ansible.cfg file.

1.  **Inventory File Format:** The inventory file can be in INI or YAML format. The INI format is more common for simple inventories.
2.  **INI Inventory Example:**

```ini
[webservers]
webserver1 ansible_host=192.168.1.10
webserver2 ansible_host=192.168.1.11

[databases]
dbserver1 ansible_host=192.168.1.20 ansible_user=dbadmin ansible_ssh_private_key_file=~/.ssh/db_rsa

[all:vars]
ansible_user=ubuntu
ansible_ssh_private_key_file=~/.ssh/id_rsa
```

In this example:

1.  \[webservers\] and \[databases\] define two groups of hosts.
2.  webserver1 and webserver2 are members of the webservers group. ansible_host specifies the IP address or hostname of each server.
3.  dbserver1 is a member of the databases group. It overrides the default ansible_user and ansible_ssh_private_key_file variables.
4.  \[all:vars\] defines variables that apply to all hosts in the inventory. This sets the default ansible_user to ubuntu and specifies the default SSH private key file.

5.  **YAML Inventory Example:**

```yaml
all:
  vars:
    ansible_user: ubuntu
    ansible_ssh_private_key_file: ~/.ssh/id_rsa
  children:
    webservers:
      hosts:
        webserver1:
          ansible_host: 192.168.1.10
        webserver2:
          ansible_host: 192.168.1.11
    databases:
      hosts:
        dbserver1:
          ansible_host: 192.168.1.20
          ansible_user: dbadmin
          ansible_ssh_private_key_file: ~/.ssh/db_rsa
```

This YAML inventory achieves the same configuration as the INI example. YAML is often preferred for more complex inventories due to its readability and flexibility.

4\. **Inventory Variables:** You can define variables at the host, group, or inventory level. These variables can be used in your playbooks to customize the configuration of your managed nodes.

1.  **Host Variables:** Defined for a specific host in the inventory.
    
2.  **Group Variables:** Defined for a group of hosts in the inventory.
    
3.  **Inventory Variables:** Defined in the \[all:vars\] section or at the top level of a YAML inventory.
    

### SSH Key Configuration

Ansible typically uses SSH keys for authentication. This is a more secure and convenient method than using passwords.

1.  **Generate SSH Key Pair:** If you don't already have an SSH key pair, you can generate one using the ssh-keygen command.
```bash
ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa -N ""
```

This command generates a 2048-bit RSA key pair and saves the private key to ~/.ssh/id\_rsa and the public key to ~/.ssh/id\_rsa.pub. The -N "" option specifies an empty passphrase, which means you won't be prompted for a password when using the key.

2. **Copy Public Key to Managed Nodes:** You need to copy the public key to the ~/.ssh/authorized\_keys file on each managed node. You can use the ssh-copy-id command to do this.
```bash
ssh-copy-id -i ~/.ssh/id_rsa.pub ubuntu@192.168.1.10
```

Replace ubuntu with the appropriate username and 192.168.1.10 with the IP address of the managed node. You will be prompted for the user's password on the managed node to complete this process.

3\. **Configure ansible.cfg:** Ensure that the private\_key\_file option in your ansible.cfg file points to the correct private key file.
```ini
[defaults]
private_key_file = ~/.ssh/id_rsa
```

Verifying the Installation
--------------------------

After installing and configuring Ansible, it's important to verify that everything is working correctly.

### Pinging Managed Nodes

The ansible command with the ping module is a simple way to check connectivity to your managed nodes.

```bash
ansible all -m ping
```

This command will attempt to ping all hosts defined in your inventory file. If successful, it will return "pong" for each host.

```
webserver1 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
webserver2 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
dbserver1 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
```

If you encounter errors, check the following:

*   **Connectivity:** Ensure that your control node can reach the managed nodes over the network.
    
*   **SSH Configuration:** Verify that SSH keys are properly configured and that you can SSH to the managed nodes without being prompted for a password.
    
*   **Inventory File:** Double-check the inventory file for any typos or incorrect hostnames/IP addresses.
    
*   **Firewall:** Ensure that firewalls on both the control node and managed nodes are not blocking SSH traffic (port 22 by default).
    

### Running Ad-Hoc Commands

Ad-hoc commands are simple, one-off tasks that you can run on your managed nodes. They are useful for quickly checking the status of a system or performing a simple action.
```bash
ansible all -m shell -a "uptime"
```

This command will execute the uptime command on all hosts in your inventory.
```bash
webserver1 | SUCCESS | rc=0 >>
 10:23:45 up 1 day,  2:15,  1 user,  load average: 0.01, 0.02, 0.00
webserver2 | SUCCESS | rc=0 >>
 10:23:45 up 1 day,  2:15,  1 user,  load average: 0.01, 0.02, 0.00
dbserver1 | SUCCESS | rc=0 >>
 10:23:45 up 1 day,  2:15,  1 user,  load average: 0.01, 0.02, 0.00
```

The -m shell option specifies that you want to use the shell module, which allows you to execute arbitrary shell commands. The -a "uptime" option specifies the arguments to pass to the shell module.

ExampleCorp Scenario
--------------------

Let's apply these concepts to the ExampleCorp project. Suppose ExampleCorp has the following infrastructure:

*   Two web servers (web1, web2) running Apache.
    
*   One database server (db1) running MySQL.
    

We can create an inventory file for ExampleCorp:
```ini
[webservers]
web1 ansible_host=192.168.10.10
web2 ansible_host=192.168.10.11

[databases]
db1 ansible_host=192.168.10.20

[all:vars]
ansible_user=examplecorp
ansible_ssh_private_key_file=~/.ssh/examplecorp_rsa
```

This inventory defines the web servers and database server for ExampleCorp. It also sets the default username and SSH private key file for all hosts. You would then need to ensure the examplecorp user exists on each managed node and that the examplecorp_rsa.pub key is added to their ~/.ssh/authorized_keys file.

To verify the installation, you could run the following command:
```bash
ansible all -m ping
```

This will check connectivity to all servers in the ExampleCorp infrastructure.

Practice Activities
-------------------

1.  **Install Ansible:** Install Ansible on your local machine or a virtual machine using the instructions provided for your operating system.
    
2.  **Configure ansible.cfg:** Create an ansible.cfg file in your home directory and configure the inventory, remote\_tmp, and private\_key\_file options.
    
3.  **Create an Inventory File:** Create an inventory file with at least three hosts. Define different groups and variables for each host.
    
4.  **Configure SSH Keys:** Generate an SSH key pair and copy the public key to your managed nodes.
    
5.  **Verify Installation:** Use the ping module and ad-hoc commands to verify that Ansible is working correctly. Try running commands like df -h to check disk space or free -m to check memory usage.
    
6.  **ExampleCorp Expansion:** Add a new application server (app1) with IP address 192.168.10.12 to the ExampleCorp inventory. Modify the inventory file accordingly and verify connectivity.
    

Summary
-------

In this lesson, you learned how to install and configure Ansible on your control node. You also learned how to create an inventory file, configure SSH keys, and verify your installation. A properly configured Ansible environment is essential for managing your infrastructure and applications effectively.

Next Steps
----------

In the next lesson, you will learn how to write your first Ansible playbook. You will learn about the basic syntax of playbooks, how to define tasks, and how to use modules to automate configuration management tasks.

Future Learning Directions
--------------------------

*   Explore advanced inventory management techniques, such as dynamic inventories and inventory plugins.
    
*   Learn about different Ansible configuration options and how to customize Ansible's behavior.
    
*   Investigate different methods for authenticating to managed nodes, such as Kerberos and SSH agent forwarding.